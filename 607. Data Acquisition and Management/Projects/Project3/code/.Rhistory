colKeep <- c("FIPStxt", "State", "Area_name", names(data3) %>% grep("Unemployment_rate_", x = ., value = T))
d3Tidy <- data3 %>%
dplyr::select(colKeep) %>%
# create a county_flag and remove state abbreviation from the Area_name
dplyr::mutate(county_flag = ifelse( str_detect(Area_name, ", "), 1, 0 ),
area_name = str_replace_all(Area_name, ", [[:upper:]]{2}", "")) %>%
dplyr::select(FIPStxt, State, county_flag, area_name, starts_with("Unemployment")) %>%
# gather the unemployment rate columns
tidyr::gather(., year, unemployment_rate,
starts_with("Unemployment")) %>%
# extract year
dplyr::mutate(year = str_extract(year, "[[:digit:]]{4}") %>% as.integer)
names(d3Tidy) <- tolower(names(d3Tidy))
###################################################################
d3Map <- d3Tidy %>%
dplyr::filter(county_flag == 1 & state != "PR") %>%
dplyr::select(year, state, fipstxt, unemployment_rate) %>%
dplyr::rename("region" = fipstxt, "value" = unemployment_rate) %>%
dplyr::filter(!is.na(value))
# Define UI for miles per gallon app ----
ui <- fluidPage(
# App title ----
titlePanel("US Unemployment Rate, 2007 - 2017"),
# Sidebar layout with input and output definitions ----
verticalLayout(wellPanel(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Selector for variable to plot ----
selectInput("year",
"Year:",
c(unique(d3Map$year)),
selected = 2017
),
selectInput("state",
"State:",
c(unique(d3Map$state)),
selected = "NY"
)
)
),
# Main panel for displaying outputs ----
mainPanel(
# add tabs
tabsetPanel(
# Outputs: ----
tabPanel("US Unemployment Rate (%)", plotOutput("USMap")),
tabPanel("State Unemployment Rate (%)", plotOutput("StateMap")),
tabPanel("State Unemployment Rate (%) - table", tableOutput("StateMapTable"))
)
)
)
)
# Define server logic to plot various variables ----
server <- function(input, output) {
stateInput <- reactive({
switch(input$state,
'AL' = 'alabama',
'AK' = 'alaska',
'AZ' = 'arizona',
'AR' = 'arkansas',
'CA' = 'california',
'Co' = 'colorado',
'CT' = 'connecticut',
'DE' = 'delaware',
'DC' = 'district of columbia',
'FL' = 'florida',
'GA' = 'georgia',
'HI' = 'hawaii',
'ID' = 'idaho',
'IL' = 'illinois',
'IN' = 'indiana',
'IA' = 'iowa',
'KS' = 'kansas',
'KY' = 'kentucky',
'LA' = 'louisiana',
'ME' = 'maine',
'MD' = 'maryland',
'MA' = 'massachusetts',
'MI' = 'michigan',
'MN' = 'minnesota',
'MS' = 'mississippi',
'MO' = 'missouri',
'MT' = 'montana',
'NE' = 'nebraska',
'NV' = 'nevada',
'NH' = 'new hampshire',
'NJ' = 'new jersey',
'NM' = 'new mexico',
'NY' = 'new york',
'NC' = 'north carolina',
'ND' = 'north dakota',
'OH' = 'ohio',
'OK' = 'oklahoma',
'OR' = 'oregon',
'PA' = 'pennsylvania',
'RI' = 'rhode island',
'SC' = 'south carolina',
'SD' = 'south dakota',
'TN' = 'tennessee',
'TX' = 'texas',
'UT' = 'utah',
'VT' = 'vermont',
'VA' = 'virginia',
'WA' = 'washington',
'WV' = 'west virginia',
'WI' = 'wisconsin',
'WY' = 'wyoming'
)
})
US_data_Input <- reactive({
d3Map %>%
dplyr::filter(year == input$year) %>%
dplyr::select(region, value)
})
State_data_Input <- reactive({
d3Map %>%
dplyr::filter(year == input$year & state == input$state) %>%
dplyr::select(region, value)
})
# Generate plots of the requested variable ----
# US Map
output$USMap <- renderPlot({
county_choropleth(US_data_Input(),
title = paste("United States", input$year),
legend = "%",
num_colors = 1)
})
# State Map
output$StateMap <- renderPlot({
county_choropleth(State_data_Input(),
title = paste(stringr::str_to_title(stateInput()), input$year),
legend = "%",
state_zoom = stateInput(),
num_colors = 1)
})
# print table output
output$StateMapTable <- renderTable({
d3Tidy %>%
dplyr::filter(county_flag == 1 & state != "PR" &
year == input$year & state == input$state) %>%
dplyr::select(area_name, unemployment_rate) %>%
dplyr::rename("county" = area_name) %>%
dplyr::filter(!is.na(unemployment_rate)) %>%
arrange(desc(unemployment_rate))
})
}
# Create Shiny app ----
shinyApp(ui, server, options = list(height = 1800, width = 2100))
quit()
# setwd("C:/Users/traveler/Desktop/SPS/607. Data Acquisition and Management/Projects/Project2/code")
library(sf)  # must load first
library(tidyverse)  # then load this one before choroplethr
# library(dplyr)
# library(stringr)
# library(ggplot2)
# library(choroplethrMaps)
library(choroplethr)
library(knitr)
library(RCurl)
library(ggrepel)
library(gridExtra)
library(sqldf)
library(shiny)
library(kableExtra)
# load file for data set 3
data3_url <- "https://raw.githubusercontent.com/myvioletrose/school_of_professional_studies/master/607.%20Data%20Acquisition%20and%20Management/Projects/Project2/data/unemployment.csv"
data3 <- data3_url %>% RCurl::getURL(.) %>% textConnection(.) %>%
read.csv(., stringsAsFactors = F, header = T)
# before tidying
head(data3) %>% kable %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
full_width = F, latex_options = "scale_down")
# let's just extract the FIPS, state, area name and all unemployment rates
# names(data3) %>% data.frame %>% arrange((.))
colKeep <- c("FIPStxt", "State", "Area_name", names(data3) %>% grep("Unemployment_rate_", x = ., value = T))
d3Tidy <- data3 %>%
dplyr::select(colKeep) %>%
# create a county_flag and remove state abbreviation from the Area_name
dplyr::mutate(county_flag = ifelse( str_detect(Area_name, ", "), 1, 0 ),
area_name = str_replace_all(Area_name, ", [[:upper:]]{2}", "")) %>%
dplyr::select(FIPStxt, State, county_flag, area_name, starts_with("Unemployment")) %>%
# gather the unemployment rate columns
tidyr::gather(., year, unemployment_rate,
starts_with("Unemployment")) %>%
# extract year
dplyr::mutate(year = str_extract(year, "[[:digit:]]{4}") %>% as.integer)
names(d3Tidy) <- tolower(names(d3Tidy))
###################################################################
d3Map <- d3Tidy %>%
dplyr::filter(county_flag == 1 & state != "PR") %>%
dplyr::select(year, state, fipstxt, unemployment_rate) %>%
dplyr::rename("region" = fipstxt, "value" = unemployment_rate) %>%
dplyr::filter(!is.na(value))
# Define UI for miles per gallon app ----
ui <- fluidPage(
# App title ----
titlePanel("US Unemployment Rate, 2007 - 2017"),
# Sidebar layout with input and output definitions ----
verticalLayout(wellPanel(
# Sidebar panel for inputs ----
sidebarPanel(
# Input: Selector for variable to plot ----
selectInput("year",
"Year:",
c(unique(d3Map$year)),
selected = 2017
),
selectInput("state",
"State:",
c(unique(d3Map$state)),
selected = "NY"
)
)
),
# Main panel for displaying outputs ----
mainPanel(
# add tabs
tabsetPanel(
# Outputs: ----
tabPanel("US Unemployment Rate (%)", plotOutput("USMap")),
tabPanel("State Unemployment Rate (%)", plotOutput("StateMap")),
tabPanel("State Unemployment Rate (%) - table", tableOutput("StateMapTable"))
)
)
)
)
# Define server logic to plot various variables ----
server <- function(input, output) {
stateInput <- reactive({
switch(input$state,
'AL' = 'alabama',
'AK' = 'alaska',
'AZ' = 'arizona',
'AR' = 'arkansas',
'CA' = 'california',
'Co' = 'colorado',
'CT' = 'connecticut',
'DE' = 'delaware',
'DC' = 'district of columbia',
'FL' = 'florida',
'GA' = 'georgia',
'HI' = 'hawaii',
'ID' = 'idaho',
'IL' = 'illinois',
'IN' = 'indiana',
'IA' = 'iowa',
'KS' = 'kansas',
'KY' = 'kentucky',
'LA' = 'louisiana',
'ME' = 'maine',
'MD' = 'maryland',
'MA' = 'massachusetts',
'MI' = 'michigan',
'MN' = 'minnesota',
'MS' = 'mississippi',
'MO' = 'missouri',
'MT' = 'montana',
'NE' = 'nebraska',
'NV' = 'nevada',
'NH' = 'new hampshire',
'NJ' = 'new jersey',
'NM' = 'new mexico',
'NY' = 'new york',
'NC' = 'north carolina',
'ND' = 'north dakota',
'OH' = 'ohio',
'OK' = 'oklahoma',
'OR' = 'oregon',
'PA' = 'pennsylvania',
'RI' = 'rhode island',
'SC' = 'south carolina',
'SD' = 'south dakota',
'TN' = 'tennessee',
'TX' = 'texas',
'UT' = 'utah',
'VT' = 'vermont',
'VA' = 'virginia',
'WA' = 'washington',
'WV' = 'west virginia',
'WI' = 'wisconsin',
'WY' = 'wyoming'
)
})
US_data_Input <- reactive({
d3Map %>%
dplyr::filter(year == input$year) %>%
dplyr::select(region, value)
})
State_data_Input <- reactive({
d3Map %>%
dplyr::filter(year == input$year & state == input$state) %>%
dplyr::select(region, value)
})
# Generate plots of the requested variable ----
# US Map
output$USMap <- renderPlot({
county_choropleth(US_data_Input(),
title = paste("United States", input$year),
legend = "%",
num_colors = 1)
})
# State Map
output$StateMap <- renderPlot({
county_choropleth(State_data_Input(),
title = paste(stringr::str_to_title(stateInput()), input$year),
legend = "%",
state_zoom = stateInput(),
num_colors = 1)
})
# print table output
output$StateMapTable <- renderTable({
d3Tidy %>%
dplyr::filter(county_flag == 1 & state != "PR" &
year == input$year & state == input$state) %>%
dplyr::select(area_name, unemployment_rate) %>%
dplyr::rename("county" = area_name) %>%
dplyr::filter(!is.na(unemployment_rate)) %>%
arrange(desc(unemployment_rate))
})
}
# Create Shiny app ----
shinyApp(ui, server, options = list(height = 1800, width = 2100))
library(shiny)
# load packages
library(tidyverse)
library(plyr)
library(Hmisc)
library(sqldf)
# load csv
setwd("C:/Users/traveler/Desktop/SPS/607. Data Acquisition and Management/Projects/Project3/code")
current_wd <- getwd()
setwd("../"); setwd("data")
df <- read.csv("indeed_job_dataset.csv", stringsAsFactors = F)
setwd(current_wd)
# extract "jk_id", "fcc_id" from link
df <- df %>%
dplyr::mutate(jk_id = str_extract_all(Link, pattern = "jk=[[:alnum:]]+&") %>%
str_replace_all(., pattern = "jk=|&", replacement = ""),
fcc_id = str_extract_all(Link, pattern = "fccid=[[:alnum:]]+&") %>%
str_replace_all(., pattern = "fccid=|&", replacement = ""))
dim(df)
# clean up header
names(df) <- tolower(names(df))
# check Ids
sapply(list(df$jk_id, df$fcc_id), function(x){length(unique(x))})
# lookup both Ids, some links are missing the "jk_id"
jk_id.lookup <- plyr::count(df, "jk_id") %>% arrange(desc(freq))
table(jk_id.lookup$freq); head(jk_id.lookup)
# "fcc_id" can be duplicated because the same company can post the same job position with different attributes, most likely offering the same position in different locations
fcc_id.lookup <- plyr::count(df, "fcc_id") %>% arrange(desc(freq))
head(fcc_id.lookup)
# the result indicates that each "jk_id" is unique in the data set; there is no duplication for any "jk_id"
# however, 99 jobs have missing "jk_id"
# why? what are these 99 jobs?
jk_id.missing <- df %>%
dplyr::filter(jk_id == "character(0)")
# write.csv(jk_id.missing, "clipboard", row.names = F)
# let's fix these "jk_id" - these are written differently as there's no "jk=" in these links
# e.g. https://www.indeed.com/company/Wag!/jobs/Data-Engineer-0633d6309b9f2be8?fccid=381733c3e1596619&vjs=3
jk_id.missing <- jk_id.missing %>%
dplyr::mutate(jk_id = str_extract_all(jk_id.missing$link, pattern = "-[[:alnum:]]+\\?fccid") %>%
str_replace_all(., pattern = "-|\\?fccid", replacement = ""))
# let's 'union all' both sets
df <- df %>%
dplyr::filter(x %nin% jk_id.missing$x) %>%
dplyr::bind_rows(., jk_id.missing)
##############################
##### data normalization #####
##############################
# we are going to create a simple star schema for this data set
# we need four tables, i.e. "job_post_specific", "job_position", "company", & "description"
# "job_post_specific" table - "jk_id" is the primary key. Each "jk_id" is unique and that represents a post for one job position from a company
# "job_position" table - beware of the original "fcc_id"! Note, the "job_post_specific" and "job_position" tables are different. The same job position is supposed to share an idential and unique "fcc_id"; however, there can be multiple posting. In other words, we expect to see the same "fcc_id" for multiple "jk_id".
# For instance, Google posted four identical position "Google AI Resident, 2019 Start (Fixed-Term Employee)" with the same "fcc_id" (a5b4499d9e91a5c6) but four different "jk_id". These four positions were offered in different locations (NY, MA, CA, & WA)
# We should consider these four positions as one when counting for skill sets; otherwise, we will inflate our numbers when calculating for the percentage based on skill sets
# However, the data is also messy in terms of some companies posted different job positions with the same "fcc_id"!
# Using Google and the same "fcc_id" (a5b4499d9e91a5c6) as an example, there are actually 40 entries in the data set that share the same "fcc_id"! That simply means that there are different job positions share the same "fcc_id", but we also have identical jobs share the same "fcc_id" with different entries in the data set because they can be offered in different locations
# one extreme case, Booz Allen Hamilton posted 151 different jobs with identical "fcc_id" (4e041af1d0af1bc8)!
# we must clean up the messy "fcc_id" before splitting up the data set into four tables
# we must 1) remove duplication of identical jobs (job_title, queried_salary, job_type, skill, company), and 2) create unique "fcc_unique_id" as the primary key
# last but not least, we also need to clean up the "company" table by creating a company Id and performing simple Change-Data-Capture
################
# job_position #
################
# distinct, create fcc_unique_id
job_position <- df %>%
dplyr::select(fcc_id, job_title, queried_salary, job_type, skill, company) %>%
dplyr::distinct() %>%
# create a "fcc_unique_id" after the dplyr::distinct()
dplyr::mutate(fcc_unique_id = paste(row_number(), fcc_id, sep = "_"))
#####################
# job_post_specific #
#####################
job_post_specific <- sqldf("
select df.jk_id
, jp.fcc_unique_id
, df.link
, df.date_since_posted
, df.location
from job_position jp
join (
select jk_id, fcc_id, job_title, queried_salary, job_type, skill, company
, link, date_since_posted, location
from df
) df on jp.fcc_id = df.fcc_id
and jp.job_title = df.job_title
and jp.queried_salary = df.queried_salary
and jp.job_type = df.job_type
and jp.skill = df.skill
and jp.company = df.company
")
# check again
sapply(list(job_position$fcc_unique_id, job_post_specific$fcc_unique_id), function(x) unique(x) %>% length)
sapply(list(df$jk_id, job_post_specific$jk_id), function(x) unique(x) %>% length)
# great, we do not lose any distinct job position or posting
# we get rid of identical jobs that share the same "fcc_id", and we also create a "fcc_unique_id" to replace the existing "fcc_id" - this way, we don't see different jobs share the same "fcc_id", and we create a unique "fcc_unique_id" for all distinct jobs
#########################
# clean-up job_position #
#########################
# create a company ID
company_index <- df %>%
dplyr::select(company) %>%
distinct() %>%
arrange(company) %>%
dplyr::mutate(company_id = paste("c", row_number(), sep = "_"))
job_position <- job_position %>%
dplyr::left_join(., company_index) %>%
dplyr::select(fcc_unique_id, job_title, queried_salary, job_type, skill, company_id)
###########
# company #
###########
company <- df %>%
dplyr::select(company, no_of_reviews, no_of_stars, company_revenue, company_employees, company_industry) %>%
distinct() %>%
dplyr::left_join(., company_index) %>%
dplyr::select(company_id, everything()) %>%
arrange(company_id)
# perform simple CDC - Chang-Data-Capture
# get rid of multiple entries by returning the max of "no_of_stars" and "no_of_reviews" b/c we suppose that's the latest update for the company
company <- sqldf("
select company_id, company, company_revenue, company_employees, company_industry
, max(no_of_stars) as no_of_stars
, max(no_of_reviews) as no_of_reviews
from company
group by 1, 2, 3, 4, 5
order by company
"
)
###############
# description #
###############
description <- df %>%
dplyr::select(link, description) %>%
distinct()
####################
# write csv output #
####################
setwd("../"); setwd("data")
write.csv(job_position, "job_position.csv", row.names = F)
write.csv(job_post_specific, "job_post_specific.csv", row.names = F)
write.csv(company, "company.csv", row.names = F)
write.csv(description, "description.csv", row.names = F)
setwd(current_wd)
ls()
keep <- c("job_position", "job_post_specific", "company", "description")
remove <- ls() %nin% keep
remove
remove <- ls[ls() %nin% keep]
ls() %nin% keep
ls()[ls() %nin% keep]
remove <- ls()[ls() %nin% keep]
rm(remove)
ls()
keep <- c("job_position", "job_post_specific", "company", "description")
remove <- ls()[ls() %nin% keep]
remove
rm(ls()[ls() %nin% keep])
ls()[ls() %nin% keep]
c(ls()[ls() %nin% keep]))
c(ls()[ls() %nin% keep])
rm(c(ls()[ls() %nin% keep]))
remove <- c(ls()[ls() %nin% keep])
remove
rm(!!remove)
deparse(substitute(remove))
eval(remove)
rm(eval(remove))
keep <- c("job_position", "job_post_specific", "company", "description")
remove <- c(ls()[ls() %nin% keep])
remove
setdiff(remove, keep)
rm(list = setdiff(remove, keep))
ls()
setwd("../")
setwd("data")
save(list = ls(), file = "data_ETL.Rda")
setwd(current_wd)
setwd("../")
setwd("code")
ls()
sapply(list = ls(), names(x))
sapply(list = ls(), names())
sapply(list = ls(), function(x) names(x))
sapply(list = ls(), function(x) {names(x)})
lapply(list = ls(), function(x) {names(x)})
lapply(ls(), function(x) {names(x)})
sapply(ls(), function(x) {names(x)})
names(company)
names(company) %>% data.frame
names(job_position) %>% data.frame
names(job_post_specific) %>% data.frame
names(description) %>% data.frame
