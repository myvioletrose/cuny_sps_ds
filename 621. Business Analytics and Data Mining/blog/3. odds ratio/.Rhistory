knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(broom)
library(Hmisc)
library(tidyr)
library(corrplot)
library(mice)
library(MASS)
library(caret)
# set working directory
setwd("~/school_of_professional_studies/621. Business Analytics and Data Mining/hw1")
# read data
dfTrain <- read.csv("moneyball-training-data.csv")
dfEval <- read.csv("moneyball-evaluation-data.csv")
# head, dim
head(dfTrain); dim(dfTrain)
head(dfEval); dim(dfEval)
# what is the difference between the two data.frames?
paste0(names(dfTrain)[names(dfTrain) %nin% names(dfEval)], " is not found in the evaluation data set")
# data structure
str(dfTrain)
# descriptive statistics
summary(dfTrain)
# length of unique value for each variable
sapply(dfTrain, function(x) unique(length(x)))
# any missing
colSums(is.na(dfTrain))
### Visualization of data distribution, spread, outliners and correlations among variables ###
# boxplot
dfTrain %>%
tidyr::gather(key, value, -INDEX) %>%
ggplot(aes(x = key, y = value, fill = key)) +
geom_boxplot() +
# scale_y_continuous(labels = scales::dollar) +
geom_boxplot(outlier.colour = "red") +
theme(legend.position = "none",
axis.title.y = element_blank()) +
coord_flip()
# corrplot
dfTrain %>%
complete.cases() %>%
dfTrain[., ] %>%
dplyr::select(-INDEX) %>%
cor() %>%
corrplot(method = "number")
# let's look at number of missing values again
colSums(is.na(dfTrain))
# let's impute missing values using the mice package
dfImpute <- dfTrain %>%
mice::mice(m = 1,  # number of imputed data set
maxit = 10,  # number of iterations to impute missing values
method = "pmm",  # method used in imputation, and we choose "predictive mean matching" for all our numeric variables
seed = 1234)
dfClean <- mice::complete(dfImpute)
str(dfClean)
# check again
colSums(is.na(dfClean))
# split into train, test
set.seed(1234)
index <- sample(1:nrow(dfClean), size = nrow(dfClean) * 0.7)
train <- dfClean[index, ]
test <- dfClean[-index, ]
# build full model
fullModel <- lm(TARGET_WINS ~., data = train %>% dplyr::select(-INDEX))
broom::glance(fullModel)
# build full model - sqrt transformation for taking care of outliners
DV <- names(dfClean)[names(dfClean) %nin% c("INDEX", "TARGET_WINS")]
fullModelSqrt <- lm(TARGET_WINS ~ ., data = train %>% dplyr::select(-INDEX) %>% dplyr::mutate_at(vars(DV), sqrt))
broom::glance(fullModelSqrt)
# stepwise regression - direction default to both
step <- MASS::stepAIC(fullModel, trace = FALSE)
step$anova
# 2 degree of interactions - full model
step2 <- MASS::stepAIC(fullModel, ~ .^2, trace = FALSE)
step2$anova
# 2 degree of interactions - sqrt transformation
step2.1 <- MASS::stepAIC(fullModelSqrt, ~.^2, trace = FALSE)
step2.1$anova
# final model (based on the sqrt transformation)
finalModelSqrt <- lm(
TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B +
TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_BATTING_SO + TEAM_BASERUN_SB +
TEAM_BASERUN_CS + TEAM_BATTING_HBP + TEAM_PITCHING_H + TEAM_PITCHING_HR +
TEAM_PITCHING_BB + TEAM_PITCHING_SO + TEAM_FIELDING_E + TEAM_FIELDING_DP +
TEAM_BATTING_BB:TEAM_FIELDING_DP + TEAM_BASERUN_SB:TEAM_PITCHING_HR +
TEAM_BATTING_SO:TEAM_BASERUN_SB + TEAM_BATTING_2B:TEAM_FIELDING_DP +
TEAM_BATTING_HBP:TEAM_PITCHING_H + TEAM_BATTING_H:TEAM_FIELDING_E +
TEAM_BATTING_HR:TEAM_PITCHING_H + TEAM_PITCHING_H:TEAM_PITCHING_SO +
TEAM_BATTING_2B:TEAM_BATTING_HR + TEAM_BATTING_3B:TEAM_PITCHING_SO +
TEAM_BATTING_H:TEAM_BATTING_HR + TEAM_BASERUN_SB:TEAM_PITCHING_H +
TEAM_PITCHING_SO:TEAM_FIELDING_E + TEAM_BATTING_BB:TEAM_FIELDING_E +
TEAM_BATTING_SO:TEAM_PITCHING_SO + TEAM_BATTING_3B:TEAM_PITCHING_H +
TEAM_BATTING_SO:TEAM_PITCHING_H + TEAM_PITCHING_H:TEAM_PITCHING_BB +
TEAM_BATTING_H:TEAM_BATTING_3B + TEAM_BATTING_HR:TEAM_BASERUN_SB +
TEAM_BATTING_BB:TEAM_BASERUN_SB + TEAM_BATTING_H:TEAM_PITCHING_SO +
TEAM_BASERUN_CS:TEAM_PITCHING_BB + TEAM_BATTING_3B:TEAM_FIELDING_E +
TEAM_BATTING_3B:TEAM_BASERUN_SB + TEAM_BATTING_HBP:TEAM_FIELDING_E +
TEAM_FIELDING_E:TEAM_FIELDING_DP + TEAM_BASERUN_SB:TEAM_PITCHING_BB +
TEAM_BATTING_SO:TEAM_FIELDING_E + TEAM_PITCHING_BB:TEAM_FIELDING_E +
TEAM_BATTING_HR:TEAM_BATTING_BB + TEAM_BATTING_2B:TEAM_BATTING_HBP +
TEAM_BATTING_2B:TEAM_BASERUN_SB + TEAM_BASERUN_SB:TEAM_PITCHING_SO +
TEAM_PITCHING_HR:TEAM_FIELDING_DP + TEAM_BASERUN_SB:TEAM_BASERUN_CS +
TEAM_BASERUN_CS:TEAM_PITCHING_HR + TEAM_BASERUN_SB:TEAM_FIELDING_DP,
data = train %>% dplyr::select(-INDEX) %>% dplyr::mutate_at(vars(DV), sqrt)
)
broom::glance(finalModelSqrt)
broom::tidy(finalModelSqrt) %>% arrange(p.value)
# diagnostic
par(mfrow = c(2, 2))
plot(finalModel)
# diagnostic
par(mfrow = c(2, 2))
plot(finalModelSqrt)
# plot predicted outcomes with actuals with confidence intervals
testFinal <- test %>%
dplyr::mutate(predictedOutcome = round(predict(finalModelSqrt,
newdata = test %>% dplyr::select(-INDEX) %>% dplyr::mutate_at(vars(DV), sqrt),
type = "response")))
test.pred <- predict(finalModelSqrt,
newdata = test %>% dplyr::select(-INDEX) %>% dplyr::mutate_at(vars(DV), sqrt),
interval = "prediction")
testCombined <- cbind(testFinal, test.pred) %>%
dplyr::select(-fit)
test.subset <- testCombined %>%
dplyr::select(target_wins = TARGET_WINS,
predicted_wins = predictedOutcome,
lwr,
upr) %>%
dplyr::filter(predicted_wins >0)
p <- test.subset%>%
ggplot(aes(target_wins, predicted_wins)) +
geom_point()
p + geom_point(aes(y = lwr), col = "red") +
geom_point(aes(y = upr), col = "green") +
geom_abline(intercept = 0, slope = 1)
# what is the correlation betweent predicted and actuals?
cor.test(test.subset$target_wins, test.subset$predicted_wins)
# what is the RMSE of this final model (sqrt transformed)?
caret::RMSE(pred = test.subset$predicted_wins, obs = test.subset$target_wins)
# finally, let's apply it to our evaluation set
colSums(is.na(dfEval))
# let's impute missing values using the mice package
dfImpute2 <- dfEval %>%
mice::mice(m = 1,  # number of imputed data set
maxit = 10,  # number of iterations to impute missing values
method = "pmm",  # method used in imputation, and we choose "predictive mean matching" for all our numeric variables
seed = 1234)
dfEvalClean <- mice::complete(dfImpute2)
dfEval$evalPredictedOutcome = round(predict(finalModelSqrt,
newdata = dfEvalClean %>% dplyr::select(-INDEX) %>% dplyr::mutate_at(vars(DV), sqrt),
type = "response"))
head(dfEval)
today <- Sys.Date()
yesterday <- Sys.Date() - 1
one_year <- yesterday - 365
one_year_month <- lubridate::floor_date(one_year, unit = "month")
start_of_month <- lubridate::floor_date(yesterday, unit = "month")
end_of_month <- lubridate::ceiling_date(yesterday, unit = "month") - 1
yesterday_day <- format(yesterday, "%d")
eopm <- yesterday - day(yesterday)
sopm <- eopm - day(eopm) + 1
last_weekday <- as.Date(ifelse(weekdays(today) == "Monday", Sys.Date() - 3, yesterday))
last_weekday_day <- format(last_weekday, "%d")
yesterday_weekday <- weekdays(yesterday)
month_days <- format(end_of_month, "%d")
month_pacing <- percent(round(as.numeric(yesterday_day) / as.numeric(month_days), 2))
month_character <- months(yesterday)
year_character <- as.numeric(format(yesterday, "%Y"))
start_of_year <- lubridate::floor_date(yesterday, unit = "year")
rm(list = ls())
pacman::p_load(
anytime,
bigrquery,
dplyr,
glue,
googleAuthR,
htmlTable,
httr,
jsonlite,
kableExtra,
lubridate,
readr,
sendmailR,
scales,
tidyr,
zoo
)
today <- Sys.Date()
yesterday <- Sys.Date() - 1
one_year <- yesterday - 365
one_year_month <- lubridate::floor_date(one_year, unit = "month")
start_of_month <- lubridate::floor_date(yesterday, unit = "month")
end_of_month <- lubridate::ceiling_date(yesterday, unit = "month") - 1
yesterday_day <- format(yesterday, "%d")
eopm <- yesterday - day(yesterday)
sopm <- eopm - day(eopm) + 1
last_weekday <- as.Date(ifelse(weekdays(today) == "Monday", Sys.Date() - 3, yesterday))
last_weekday_day <- format(last_weekday, "%d")
yesterday_weekday <- weekdays(yesterday)
month_days <- format(end_of_month, "%d")
month_pacing <- percent(round(as.numeric(yesterday_day) / as.numeric(month_days), 2))
month_character <- months(yesterday)
year_character <- as.numeric(format(yesterday, "%Y"))
start_of_year <- lubridate::floor_date(yesterday, unit = "year")
today
ls()
one_year
yesterday
one_year_month
start_of_month
end_of_month
yesterday_day
eopm
eopm
sopm
eopm
sopm
last_weekday
last_weekday_day
yesterday_weekday
month_days
month_days
month_pacing <- percent(round(as.numeric(yesterday_day) / as.numeric(month_days), 2))
month_pacing
yesterday_day
month_days
month_pacing
month_character
year_character
start_of_year
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
# load packages
if(!require(pacman)){install.packages("pacman"); require(pacman)}
packages <- c('tidyverse', 'sqldf', 'broom', 'survival', 'survminer', 'kableExtra')
pacman::p_load(char = packages)
# head, dim
df <- read.csv("df.csv")
head(df)
dim(df)
# check missing
colSums(is.na(df))
# billing periods
unique(df$billing_period)
# billing periods x status
ftable(df$billing_period, df$status)
# average number of payment received by billing period
aggregate(lifetime ~ billing_period, data = df, FUN = mean)
# nest data, i.e. data = c(status, lifetime)
dfNest <- df %>%
dplyr::select(billing_period, status, lifetime) %>%
dplyr::mutate(status = dplyr::case_when(status == 'Active' ~ 1, TRUE ~ 2)) %>%
nest(., data = c(status, lifetime)) %>%
arrange(billing_period)
dfNest
# build model for overall survival - (estimate lifetime for new subscriptions)
overall_survival <- lapply(dfNest$data, function(x) survfit(Surv(lifetime, status) ~ 1, data = x))
names(overall_survival) <- dfNest$billing_period
# tidy result output
overall_survival_result <- lapply(1:length(overall_survival),
function(x) tidy(overall_survival[[x]]) %>%
dplyr::mutate(billing_period = names(overall_survival[x])))
# combine results (from list) into one dataframe
overall_survival_result <- overall_survival_result %>%
dplyr::bind_rows(.) %>%
dplyr::select(billing_period, lifetime = time, everything())
overall_survival_result %>% kable()
ggsurvplot(
fit = survfit(Surv(lifetime, status) ~ billing_period, data = unnest(dfNest)),
xlab = "Payments",
ylab = "Overall survival probability")
# option 1
option_1 <- overall_survival_result %>% group_by(billing_period) %>% summarise(lifetime = sum(estimate))
option_1 <- option_1 %>% dplyr::mutate(lifetime = floor(lifetime))
option_1
# option 2
# create 'expectancy' table - a fixed number of outcomes (possible number of payments) for each payment cohort
billing_periods_list <- list("Annual", "Month", "Semi_Annual", "Two_Years")
# set the maximum number of payment equal to 4 years
lifetime_list <- list(Annual = c(0:4), Month = c(0:48), Semi_Annual = c(0:8), Two_Years = c(0:2))
expectancy <- purrr::map2(billing_periods_list, lifetime_list, function(x, y) expand.grid(x, y)) %>%
dplyr::bind_rows(.) %>%
dplyr::select(billing_period = Var1,
lifetime = Var2)
# left join with the above model result output
modelOutput <- expectancy %>%
dplyr::left_join(., overall_survival_result, by = c("billing_period" = "billing_period", "lifetime", "lifetime")) %>%
dplyr::select(billing_period, lifetime, estimate) %>%
arrange(billing_period, lifetime)
modelOutput %>% kable()
# decay function
for(i in 1:nrow(modelOutput)){
if(!is.na(modelOutput$estimate[i])) {
next
} else {
modelOutput$estimate[i] <- dplyr::lag(modelOutput$estimate, 1)[i] / dplyr::lag(modelOutput$estimate, 2)[i] * dplyr::lag(modelOutput$estimate, 1)[i]
}
}
modelOutput %>% kable()
# sum up the estimate to get E(x)
option_2 <- modelOutput %>%
dplyr::mutate(estimate = dplyr::case_when(is.nan(estimate) ~ 0,
TRUE ~ estimate)) %>%
group_by(billing_period) %>%
summarise(periods_remaining = sum(estimate)) %>%
dplyr::mutate(periods_remaining = floor(periods_remaining))
# comparison between option 1 and 2
option_1
option_2
rm(list = ls())
setwd("~/school_of_professional_studies/621. Business Analytics and Data Mining/blog/3. odds ratio")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse, quietly = TRUE)
library(sqldf, quietly = TRUE)
library(kableExtra, quietly = TRUE)
library(Hmisc, quietly = TRUE)
df <- read.csv("demoDf.csv")
dim(df)
head(df, 20) %>% kable()
# unique values
dfUV <- lapply(df, function(x) length(unique(x))) %>%
unlist %>%
as.data.frame() %>%
rownames_to_column() %>%
dplyr::select(columns = rowname, unique_values = ".")
# missing
dfMissing <- colSums(is.na(df)) %>%
as.data.frame() %>%
rownames_to_column() %>%
dplyr::select(columns = rowname, missing = ".")
# data type
dfClass <- lapply(df, function(x) class(x)) %>%
unlist %>%
as.data.frame() %>%
rownames_to_column() %>%
dplyr::select(columns = rowname, class = ".")
# metadata
dfMeta <- dplyr::inner_join(dfUV, dfMissing,
by = c("columns", "columns")) %>%
dplyr::inner_join(dfClass, by = c("columns", "columns"))
dfMeta %>% kable()
# replace NA with "UNKNOWN" (optional)
dfClean <- lapply(1:length(names(df)), function(x) df %>%
dplyr::select(names(df)[x]) %>%
unlist %>%
as.vector %>%
replace_na("UNKNOWN")) %>%
bind_cols()
names(dfClean) <- names(df)
# gather data into appropriate structure
dfOR <- dfClean %>%
dplyr::select(-id) %>%
tidyr::gather(attribute, value, -vip)
head(dfOR, 20) %>% kable()
# a quick hack in sql
OR <- sqldf::sqldf("
select attribute
, value
, interest_group_yes
, control_group_yes
, interest_group_no
, control_group_no
from (
select x.attribute
, x.value
, x.interest_group_yes
, x.control_group_yes
, y.interest_group_total - x.interest_group_yes as interest_group_no
, y.control_group_total - x.control_group_yes as control_group_no
from (
select attribute
, value
, sum(case when vip = 1 then 1 else 0 end) as interest_group_yes
, sum(case when vip = 0 then 1 else 0 end) as control_group_yes
from dfOR
group by 1, 2
) x
join (
select attribute
, sum(case when vip = 1 then 1 else 0 end) as interest_group_total
, sum(case when vip = 0 then 1 else 0 end) as control_group_total
from dfOR
group by 1
) y on x.attribute = y.attribute
) z
where interest_group_yes >= 25
and interest_group_no >= 25
and control_group_yes >= 25
and control_group_no >= 25
"
)
# Odds Ratio
ORplusCI <- OR %>%
dplyr::mutate(OR = round((interest_group_yes / interest_group_no) / (control_group_yes / control_group_no), 4))
# Upper 95% CI
Upper_CI = with(ORplusCI,
exp(1) ^(log(OR) +
(1.96 * sqrt(1/interest_group_yes +
1/interest_group_no +
1/control_group_yes +
1/control_group_no))))
# Lower 95% CI
Lower_CI = with(ORplusCI,
exp(1) ^(log(OR) -
(1.96 * sqrt(1/interest_group_yes +
1/interest_group_no +
1/control_group_yes +
1/control_group_no))))
# combined
ORplusCI$Upper_CI <- round(Upper_CI, 4)
ORplusCI$Lower_CI <- round(Lower_CI, 4)
ORplusCI <- ORplusCI %>% dplyr::filter(!is.na(value)) %>%
dplyr::mutate(flag = length(value)) %>%
dplyr::filter(attribute %nin% c("status", "industry", "credit_card_brand", "credit_card_funding")) %>%
dplyr::select(-flag)
# display only significant results and sort by OR and sort by OR
ORplusCI <- ORplusCI %>%
dplyr::filter(Upper_CI >1 & Lower_CI >1) %>%
dplyr::mutate(OR = round(OR, 2),
Upper_CI = round(Upper_CI, 2),
Lower_CI = round(Lower_CI, 2)) %>%
arrange(desc(OR))
ORplusCI %>% kable()
