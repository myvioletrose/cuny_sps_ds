# print out a list of invalid tickers
if(length(stock) != length(symbols)){
sapply(setdiff(stock, symbols) %>% as.data.frame %>% dplyr::select(`A list of invalid ticker` = "."), function(x) print(paste0(x, " cannot be fetched from quantmod")))
}
# return a single list of xts objects from the valid symbols
if(REAL_TIME){
xtsList <- vector(mode = "list", length = length(symbols))
for(i in 1:length(symbols)){
xtsList[[i]] <- quantmod::getSymbols(
symbols[i],
env = NULL,  # set env = NULL and that is equivalent to auto.assign = FALSE
src = "av",
periodicity = "daily",
output.size = "full",
adjusted = TRUE,
api.key = ALPHA_VANTAGE_API
)
Sys.sleep(12)
}
} else {
xtsList <- foreach::foreach(i = 1:length(symbols)) %dopar% { quantmod::getSymbols(symbols[i], env = NULL, adjusted = TRUE) }  # set env = NULL and that is equivalent to auto.assign = FALSE
}
# return a single list of xts objects from the valid symbols - REAL_TIME
# xtsList <- foreach::foreach(i = 1:length(symbols)) %dopar% { quantmod::getSymbols(symbols[i],
#                                                                                   env = NULL,  # set env = NULL and that is equivalent to auto.assign = FALSE
#                                                                                   src = "av",
#                                                                                   periodicity = "daily",
#                                                                                   interval = "1min",
#                                                                                   output.size = "full",
#                                                                                   adjusted = TRUE,
#                                                                                   api.key = ALPHA_VANTAGE_API
# ) }
# Error in { : task 3 failed - "Unable to import "COST".
# getSymbols.av: Thank you for using Alpha Vantage! Our standard API call frequency is 5 calls per minute and 500 calls per day. Please visit https://www.alphavantage.co/premium/ if you would like to target a higher API call frequency."
# get names for xtsList
names(xtsList) <- symbols
# stop the cluster
# parallel::stopCluster(cl)
# source all functions
sapply(paste(FUNCTION_DIRECTORY, grep(pattern = "\\.[Rr]$", list.files(FUNCTION_DIRECTORY), value = TRUE), sep = "/"), function(x) source(x)) %>% invisible()
# stop - get data
toc(log = TRUE)
# bullish, bearish
marketTrend = c("bullish", "bearish")
# predictedValue percentile threshold, e.g. top 5% and bottom 5% price change (cl_n_diff / close)
cl_percentile_threshold = 0.05
# today value
t = 0
# today +1 value
t_plus_1 = -1
# xts subset
xts_data_subset = FALSE
# xts subset partition
xts_data_subset_partition = 500
# lag day
lday = 1
# next day(s)
n_period = 1:20
# train, test methodology
trainMethods <- c("random split", "kfold", "svm")
# seed, size
seed = 1234
size = 0.8
# random split (if not, create subset for test group partitioned by date)
test_group_random_split = TRUE
test_group_start_date <- Sys.Date() -90
test_group_end_date <- Sys.Date()
# output
modelSummaryList <- vector(mode = "list")
modelResultList <- vector(mode = "list")
testResponseYN = TRUE
if(testResponseYN){assign("testResponseList", value = vector(mode = "list"))}
# accuracy, prediction
accuracy_index <- vector(mode = "list")
prediction_index <- vector(mode = "list")
# start nested for() loop
tic("run nested for() loop")
# start nested for() loop
for(ml in trainMethods){
for(b in marketTrend){
for(i in n_period){
nday = i
for(j in stock){
# get data
x <- xtsList[[j]]
# IV
IV <- c(
'open',
'high',
'low',
'close',
'volume',
'rsi_close',
'cci_close',
'macd_close',
'signal_close',
'op_l',
'hi_l',
'lo_l',
'cl_l',
'vol_l',
'sma_5',
'sma_20',
'sma_60'
)
# get predictedValue threshold
y.t <- historicalTransformation(x, l = lday, n = nday, transformOnly = TRUE) %>%
dplyr::mutate(percent_diff = cl_n_diff / close) %>%
dplyr::filter(date <= '2020-02-21')
y <- y.t$percent_diff
y <- y[!is.na(y)]
z <- quantile(y, c(cl_percentile_threshold, 1 - cl_percentile_threshold))
# transform, get DV, set partition
x.t <- historicalTransformation(x, l = lday, n = nday, transformOnly = TRUE) %>%
dplyr::filter(date <= '2020-02-21') %>%
dplyr::mutate(
sma_5 = TTR::SMA(close, 5),
sma_20 = TTR::SMA(close, 20),
sma_60 = TTR::SMA(close, 60),
predictedValue = dplyr::case_when(b == "bullish" ~ ifelse( (cl_n_diff / close) > z[2], 1, 0 ),
TRUE ~ ifelse( (cl_n_diff / close) < z[1], 1, 0 )),
# predictedValue = as.factor(predictedValue),
partition = (nrow(.)-1):0) %>%  # 0 is referred to the most recent (or last) trading day
arrange(desc(partition))
# filter by subset partition, scale vars
if(xts_data_subset){
x.t.subset <- x.t %>%
dplyr::filter(partition <= xts_data_subset_partition) %>%
dplyr::mutate_at(vars(IV), scale)
} else {
x.t.subset <- x.t %>%
dplyr::mutate_at(vars(IV), scale)
}
# clean df
df <- x.t.subset %>%
complete.cases() %.>%
x.t.subset[., ] %>%
dplyr::select(date, all_of(IV), predictedValue)
############## <<< build model begin >>> ##############
# random split + logistics regression
if(ml == "random split"){
# split train, test group
set.seed(seed + nday)
index <- sample(1:nrow(df), size = nrow(df) * size)
if(test_group_random_split){
train <- df[index, ]
test <- df[-index, ]
} else {
train <- df %>% dplyr::filter(date < test_group_start_date)
test <- df %>% dplyr::filter(date >= test_group_start_date & date <= test_group_end_date)
}
# model - logistics regression
model <- glm(predictedValue ~ ., data = train %>% dplyr::select(-date), family = binomial(link = "logit"))
# prediction
predicted <- predict(model, test, type = "response")
# find cut off
optCutOff <- InformationValue::optimalCutoff(test$predictedValue, predicted)[1]
# model summary output
tempModelList <- list(
s <- broom::tidy(anova(model, test = "Chisq")) %>%
dplyr::mutate(trend = b,
symbol = j,
n_period = nday,
trainMethod = ml) %>%
dplyr::select(trend, symbol, n_period, trainMethod, everything())
)
modelSummaryList <<- c(modelSummaryList, tempModelList)
}
# k-fold cross-validation + logistics regression
if(ml == "kfold"){
# repeated, k-fold cross-validation
set.seed(seed + nday)
train.control <- caret::trainControl(method = "repeatedcv", number = 10, repeats = 10)
index <- sample(1:nrow(df), size = nrow(df) * size)
test <- df[-index, ]
# model - logistics regression
model <- caret::train(predictedValue ~ ., data = df %>% dplyr::select(-date), method = "glm", trControl = train.control)
# prediction
predicted <- predict(model, test, type = "raw")
# find cut off
optCutOff <- InformationValue::optimalCutoff(test$predictedValue, predicted)[1]
# model summary output
tempModelList <- list(
s <- broom::tidy(anova(model$finalModel, test = "Chisq")) %>%
dplyr::mutate(trend = b,
symbol = j,
n_period = nday,
trainMethod = ml) %>%
dplyr::select(trend, symbol, n_period, trainMethod, everything())
)
modelSummaryList <<- c(modelSummaryList, tempModelList)
}
# k-fold cross-validation + svm
if(ml == "svm"){
# repeated, k-fold cross-validation
set.seed(seed + nday)
train.control <- caret::trainControl(method = "repeatedcv", number = 10, repeats = 10)
index <- sample(1:nrow(df), size = nrow(df) * size)
test <- df[-index, ]
# model - SVM
model <- e1071::svm(predictedValue ~ ., data = df %>% dplyr::select(-date), kernel = "radial", trControl = train.control)
# svm_tune <- e1071::tune(svm, predictedValue ~ ., data = df %>% dplyr::select(-date),
#                        kernel = "radial",
#                        trControl = train.control,
#                        ranges = list(epsilon = seq(0, 1, 0.01), cost = 2^(2:9)))
#model <- svm_tune$best.model
# prediction
predicted <- predict(model, test, type = "raw")
# find cut off
optCutOff <- InformationValue::optimalCutoff(test$predictedValue, predicted)[1]
# model summary output
# tempModelList <- list(s <- tidy(summary(model) %>% as.character()))
# modelSummaryList <<- c(modelSummaryList, tempModelList)
}
############## <<< build model end >>> ##############
# diagnostic - Confusion Matrix, i.e. the columns are actuals, while rows are predicteds
cm <- InformationValue::confusionMatrix(test$predictedValue, predicted, threshold = optCutOff)
TN <- if(is.null(cm[1, 1])){NA} else {cm[1, 1]}
FN <- if(is.null(cm[1, 2])){NA} else {cm[1, 2]}
FP <- if(is.null(cm[2, 1])){NA} else {cm[2, 1]}
TP <- if(is.null(cm[2, 2])){NA} else {cm[2, 2]}
# diagnostic
auroc <- if(is.nan(InformationValue::AUROC(test$predictedValue, predicted))){NA} else {InformationValue::AUROC(test$predictedValue, predicted)}
misCE <- if(is.nan(InformationValue::misClassError(test$predictedValue, predicted, threshold = optCutOff))){NA} else {InformationValue::misClassError(test$predictedValue, predicted)}
pre <- if(is.nan(InformationValue::precision(test$predictedValue, predicted, threshold = optCutOff))){NA} else {InformationValue::precision(test$predictedValue, predicted)}
sen <- if(is.nan(InformationValue::sensitivity(test$predictedValue, predicted, threshold = optCutOff))){NA} else {InformationValue::sensitivity(test$predictedValue, predicted)}
spe <- if(is.nan(InformationValue::specificity(test$predictedValue, predicted, threshold = optCutOff))){NA} else {InformationValue::specificity(test$predictedValue, predicted)}
# diagnostic output
tempList <- list(
data.frame(trend = b,
version = paste0(j, "_n_", nday),
trainMethod = ml,
misClass = misCE,
auroc = auroc,
precision = pre,
sensitivity = sen,
specificity = spe,
TP,
FP,
TN,
FN)
)
modelResultList <<- c(modelResultList, tempList)
# result - test + response output
if(testResponseYN){
tempTestList <- list(
x <- test %>%
dplyr::mutate(trend = b,
version = paste0(j, "_n_", nday),
trainMethod = ml,
predictedValue_fr_model = ifelse(predicted > optCutOff, 1, 0),
response_cal_fr_model = predicted) %>%
dplyr::select(date, trend, version, trainMethod, predictedValue_fr_model, response_cal_fr_model) %>%
merge(x.t, by = c("date", "date"))
)
testResponseList <<- c(testResponseList, tempTestList)
}
# accuracy output
acc.subset <- x.t.subset %>%
dplyr::select(date, all_of(IV), predictedValue, partition)
acc.subset <- acc.subset %>%
complete.cases() %.>%
acc.subset[., ]
accuracyDf <- acc.subset %>%
dplyr::mutate(trend = b,
version = paste0(j, "_n_", nday),
trainMethod = ml,
prediction = predict(model, acc.subset, type = if(ml == "random split"){"response"} else {"raw"}),
prediction = dplyr::case_when(prediction >optCutOff ~ 1, TRUE ~ 0),
accuracy = dplyr::case_when(prediction == predictedValue ~ 1, TRUE ~0),
accuracy_for = partition - nday) %>%
dplyr::select(date, trend, version, trainMethod, prediction, accuracy, partition, accuracy_for)
tempDf <- list(accuracyDf)
accuracy_index <<- c(accuracy_index, tempDf)
# prediction output
pred.subset <- x.t.subset %>%
dplyr::select(date, all_of(IV))
pred.subset <- pred.subset %>%
complete.cases() %.>%
pred.subset[., ]
predictionDf <- pred.subset %>%
dplyr::mutate(trend = b,
version = paste0(j, "_n_", nday),
trainMethod = ml,
prediction = predict(model, pred.subset, type = if(ml == "random split"){"response"} else {"raw"}),
prediction = dplyr::case_when(prediction >optCutOff ~ 1, TRUE ~ 0)) %>%
dplyr::select(date, trend, version, trainMethod, prediction)
tempDf2 <- list(predictionDf)
prediction_index <<- c(prediction_index, tempDf2)
}
}
}
}
# stop - after nested for() loop
toc(log = TRUE)
tempDf <- xtsList[["UBER"]]
tempDf <- historicalTransformation(tempDf, transformOnly = TRUE) %>%
dplyr::select(date, close) %>%
dplyr::filter(date <= '2020-02-21')
accuracy_partition_index <- accuracy_index %>%
dplyr::bind_rows() %>%
dplyr::select(date, trend, version, trainMethod, partition) %>%
distinct()
accuracy_df <- accuracy_index %>%
dplyr::bind_rows() %>%
dplyr::select(trend, version, trainMethod, accuracy, accuracy_for) %>%
dplyr::inner_join(accuracy_partition_index, by = c("accuracy_for" = "partition", "version" = "version", "trend" = "trend", "trainMethod" = "trainMethod")) %>%
tidyr::separate(col = version, into = c("symbol", "n_period"), sep = "_n_") %>%
group_by(date, trend, trainMethod, symbol) %>%
summarise(accuracy = mean(accuracy))
prediction_df <- prediction_index %>%
dplyr::bind_rows() %>%
dplyr::select(date, trend, version, trainMethod, prediction) %>%
tidyr::separate(col = version, into = c("symbol", "n_period"), sep = "_n_") %>%
group_by(date, trend, trainMethod, symbol) %>%
summarise(prediction = mean(prediction))
accuracy_prediction_df <- prediction_df %>%
dplyr::left_join(accuracy_df, by = c("date" = "date", "trend" = "trend", "trainMethod" = "trainMethod", "symbol" = "symbol"))
accuracy_prediction_df <- accuracy_prediction_df %>%
merge(tempDf) %>%
dplyr::mutate(sma_5 = TTR::SMA(close, 5),
sma_20 = TTR::SMA(close, 20),
sma_60 = TTR::SMA(close, 60))
# SMA
accuracy_prediction_df %>%
dplyr::select(date, close, sma_5, sma_20, sma_60) %>%
# dplyr::filter(date >= Sys.Date() - 200) %>%
distinct() %>%
tidyr::gather(key, value, -date) %>%
ggplot(aes(date, value)) +
geom_line(aes(col = key)) +
scale_x_date(labels = scales::date_format("%Y-%m-%d"), date_breaks = "2 day") +
scale_color_manual(values = c("red", "black", "blue", "purple"),
) +
theme(legend.position = "top",
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(hjust = 1, angle = 60),
legend.background = element_rect(colour = "black"),
legend.title = element_blank()) +
scale_y_continuous(labels = scales::dollar) -> chart1
# bearish vs. bullish
accuracy_prediction_df %>%
dplyr::select(date, trend, trainMethod, accuracy, prediction) %>%
dplyr::filter(date >= Sys.Date() - 200) %>%
tidyr::gather(key, value, -date, -trend, -trainMethod) %>%
ggplot(aes(date, value,
group = interaction(key, trainMethod),
colour = key)) +
geom_line(aes(linetype = trainMethod)) +
geom_point(aes(shape = trainMethod)) +
scale_x_date(labels = scales::date_format("%Y-%m-%d"), date_breaks = "2 day") +
theme(legend.position = "top",
plot.title = element_text(hjust = 0.5),
axis.text.x = element_text(hjust = 1, angle = 60),
legend.background = element_rect(colour = "black"),
legend.title = element_blank()) +
scale_y_continuous(labels = scales::percent) +
facet_wrap(~ trend, nrow = 2) -> chart2
windows()
# grid.arrange(chart1, chart2, nrow = 1)
# ggplotly(chart2)
chart2
# stop the cluster
parallel::stopCluster(cl)
# end section
toc()
ggplotly(chart2)
chart1
chart1
chart2
rm(list = ls())
setwd("~")
dir()
setwd(file.choose())
setwd("~/school_of_professional_studies/621. Business Analytics and Data Mining/hw1")
dir()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
# read data
dfTrain <- read.csv("moneyball-training-data.csv")
dfEval <- read.csv("moneyball-evaluation-data.csv")
head(dfTrain); dim(dfTrain)
head(dfEval); dim(dfEval)
names(dfTrain)
names(dfEval)
library(Hmisc)
names(dfTrain) %nin% names(dfEval)
names(dfTrain)[names(dfTrain) %nin% names(dfEval)]
# what is the difference between the two data.frames?
paste0(names(dfTrain)[names(dfTrain) %nin% names(dfEval)], " is not found in the evaluation data set"
# what is the difference between the two data.frames?
paste0(names(dfTrain)[names(dfTrain) %nin% names(dfEval)], " is not found in the evaluation data set")
paste0(names(dfTrain)[names(dfTrain) %nin% names(dfEval)], " is not found in the evaluation data set")
summary(dfTrain)
# descriptive statistics
summary(dfTrain)
library(broom)
broom::tidy(dfTrain %>% summary)
broom::tidy(summary(dfTrain))
str(dfTrain)
head(dfTrain)
sapply(dfTrain, function(x) unique(length(x)))
# descriptive statistics
summary(dfTrain)
colSums(is.na(dfTrain))
summary(dfTrain)
windows()
df <- dfTrain %>%
gather(-index)
library(tidyr)
df <- dfTrain %>%
gather(-index)
head(dfTrain)
df <- dfTrain %>%
tidyr::gather(-INDEX)
df <- dfTrain %>%
tidyr::gather(key, value, -INDEX)
df
boxplot(value ~ key, data = df, col = key)
boxplot(value ~ key, data = df, col = df$key)
boxplot(value ~ key, data = df)
ggplot(df, aes(x = key, y = value, fill = key)) +
geom_boxplot() +
# scale_y_continuous(labels = scales::dollar) +
geom_boxplot(outlier.colour = "red") +
theme(legend.position = "none",
axis.title.y = element_blank()) +
coord_flip()
dfTrain %>%
tidyr::gather(key, value, -INDEX) %>%
ggplot(aes(x = key, y = value, fill = key)) +
geom_boxplot() +
# scale_y_continuous(labels = scales::dollar) +
geom_boxplot(outlier.colour = "red") +
theme(legend.position = "none",
axis.title.y = element_blank()) +
coord_flip()
library(corrplot)
install.packages("corrplot")
library(corrplot)
library(tidyverse)
library(broom)
library(Hmisc)
library(tidyr)
library(corrplot)
windows()
dfTrain %>%
tidyr::gather(key, value, -INDEX) %>%
ggplot(aes(x = key, y = value, fill = key)) +
geom_boxplot() +
# scale_y_continuous(labels = scales::dollar) +
geom_boxplot(outlier.colour = "red") +
theme(legend.position = "none",
axis.title.y = element_blank()) +
coord_flip()
m <- cor(dfTrain %>% dplyr::select(-INDEX))
corrplot(m, method = "circle")
corrplot(m, method = "number")
dfClean <- dfTrain %>%
complete.cases() %.>%
dfTrain[., ] %>%
dplyr::select(-INDEX)
dfClean <- dfTrain %>%
complete.cases() %>%
dfTrain[., ] %>%
dplyr::select(-INDEX)
# corrplot
dfClean <- dfTrain %>%
complete.cases() %>%
dfTrain[., ] %>%
dplyr::select(-INDEX) %>%
cor()
corrplot(dfClean, method = "number")
corrplot(dfClean, method = "number")
windows()
corrplot(dfClean, method = "number")
### Visualization of data distribution, spread, outliners and correlations among variables ###
# boxplot
dfTrain %>%
tidyr::gather(key, value, -INDEX) %>%
ggplot(aes(x = key, y = value, fill = key)) +
geom_boxplot() +
# scale_y_continuous(labels = scales::dollar) +
geom_boxplot(outlier.colour = "red") +
theme(legend.position = "none",
axis.title.y = element_blank()) +
coord_flip()
# corrplot
dfClean <- dfTrain %>%
complete.cases() %>%
dfTrain[., ] %>%
dplyr::select(-INDEX) %>%
cor()
corrplot(dfClean, method = "number")
### Visualization of data distribution, spread, outliners and correlations among variables ###
# boxplot
dfTrain %>%
tidyr::gather(key, value, -INDEX) %>%
ggplot(aes(x = key, y = value, fill = key)) +
geom_boxplot() +
# scale_y_continuous(labels = scales::dollar) +
geom_boxplot(outlier.colour = "red") +
theme(legend.position = "none",
axis.title.y = element_blank()) +
coord_flip()
# corrplot
dfClean <- dfTrain %>%
complete.cases() %>%
dfTrain[., ] %>%
dplyr::select(-INDEX) %>%
cor()
corrplot(dfClean, method = "number")
