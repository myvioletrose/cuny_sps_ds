metaDataTrain <- data.frame(fields = names(dfTrain),
missing = colSums(is.na(dfTrain)),
unique = sapply(dfTrain, function(x) length(unique(x))),
type = sapply(dfTrain, class))
metaDataEval <- data.frame(fields = names(dfEval),
missing = colSums(is.na(dfEval)),
unique = sapply(dfEval, function(x) length(unique(x))),
type = sapply(dfEval, class))
metaDataTrain
metaDataEval
# let's clean up variable names and remove the index column
dfTrain <- janitor::clean_names(dfTrain) %>% dplyr::select(-i_index)
# read data
dfTrain <- read.csv("wine-training-data.csv", header = TRUE)
dfEval <- read.csv("wine-evaluation-data.csv", header = TRUE)
# dim
lapply(list(dfTrain, dfEval), function(x) dim(x))
metaDataTrain <- data.frame(fields = names(dfTrain),
missing = colSums(is.na(dfTrain)),
unique = sapply(dfTrain, function(x) length(unique(x))),
type = sapply(dfTrain, class))
metaDataEval <- data.frame(fields = names(dfEval),
missing = colSums(is.na(dfEval)),
unique = sapply(dfEval, function(x) length(unique(x))),
type = sapply(dfEval, class))
metaDataTrain
metaDataEval
# let's clean up variable names and remove the index column
dfTrain <- janitor::clean_names(dfTrain) %>% dplyr::select(-i_index)
dfEval <- janitor::clean_names(dfEval) %>% dplyr::select(-`in`)
# corrplot
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(, method = "circle")
# corrplot
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(, method = "color", type = "upper")
# corrplot
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(., method = "shade", type = "upper")
metaDataTrain
head(dfTrain)
head(dfTrain)
metaDataTrain
# read data
dfTrain <- read.csv("wine-training-data.csv", header = TRUE)
dfEval <- read.csv("wine-evaluation-data.csv", header = TRUE)
# dim
lapply(list(dfTrain, dfEval), function(x) dim(x))
# head
head(dfTrain)
# let's clean up variable names and remove the index column
dfTrain <- janitor::clean_names(dfTrain) %>% dplyr::select(-i_index)
dfEval <- janitor::clean_names(dfEval) %>% dplyr::select(-`in`)
# meta data
metaDataTrain <- data.frame(fields = names(dfTrain),
missing = colSums(is.na(dfTrain)),
unique = sapply(dfTrain, function(x) length(unique(x))),
type = sapply(dfTrain, class))
metaDataEval <- data.frame(fields = names(dfEval),
missing = colSums(is.na(dfEval)),
unique = sapply(dfEval, function(x) length(unique(x))),
type = sapply(dfEval, class))
metaDataTrain
metaDataEval
metaDataTrain
windows()
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(., method = "shade", type = "upper")
windows()
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(., method = "shade", type = "upper")
dfGather <- dfTrain %>%
dplyr::select(-label_appeal, - acid_index, -stars) %>%
dplyr::mutate(target = as.factor(target)) %>%
tidyr::gather(key, value, -target)
windows()
ggplot(dfGather, aes(value, color = target)) +
geom_density() +
geom_vline(data = aggregate(value ~ target + key, dfGather, median),
aes(xintercept = value,
color = target),
linetype = "dashed") +
facet_wrap(~ key, nrow = 5, scales = "free")
# corrplot
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(., method = "shade", type = "upper")
# density curve
dfGather <- dfTrain %>%
dplyr::select(-label_appeal, - acid_index, -stars) %>%
dplyr::mutate(target = as.factor(target)) %>%
tidyr::gather(key, value, -target)
ggplot(dfGather, aes(value, color = target)) +
geom_density() +
geom_vline(data = aggregate(value ~ target + key, dfGather, median),
aes(xintercept = value,
color = target),
linetype = "dashed") +
facet_wrap(~ key, nrow = 5, scales = "free")
# corrplot
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(., method = "shade", type = "upper")
# density curve
dfGather <- dfTrain %>%
dplyr::select(-label_appeal, - acid_index, -stars) %>%
dplyr::mutate(target = as.factor(target)) %>%
tidyr::gather(key, value, -target)
ggplot(dfGather, aes(value, color = target)) +
geom_density() +
geom_vline(data = aggregate(value ~ target + key, dfGather, median),
aes(xintercept = value,
color = target),
linetype = "dashed") +
facet_wrap(~ key, nrow = 5, scales = "free")
packages <- c('tidyverse', 'sqldf', 'broom', 'caret', 'kableExtra', 'janitor', 'Hmisc', 'MASS', 'corrplot', 'Metrics', 'purrr', 'janitor', 'gridExtra')
pacman::p_load(char = packages)
packages <- c('tidyverse', 'sqldf', 'broom', 'caret', 'kableExtra', 'janitor', 'Hmisc', 'MASS', 'corrplot', 'Metrics', 'purrr', 'janitor', 'gridExtra', 'ggmosaic')
pacman::p_load(char = packages)
la <- dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, label_appeal), fill = target), na.rm = TRUE)
la <- dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, label_appeal), fill = target), na.rm = TRUE) +
labs(x = "label_appeal")
la
la <- dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, label_appeal), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "label_appeal")
la
windows()
la
la <- dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, label_appeal), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "label_appeal", fill = "Target")
windows()
la
# corrplot
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(., method = "shade", type = "upper")
# density curve
dfGather <- dfTrain %>%
dplyr::select(-label_appeal, -acid_index, -stars) %>%
dplyr::mutate(target = as.factor(target)) %>%
tidyr::gather(key, value, -target)
ggplot(dfGather, aes(value, color = target)) +
geom_density() +
geom_vline(data = aggregate(value ~ target + key, dfGather, median),
aes(xintercept = value,
color = target),
linetype = "dashed") +
facet_wrap(~ key, nrow = 5, scales = "free")
# mosaic plot
dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, label_appeal), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "label_appeal", fill = "Target") +
ggtitle("Mosaic Plot : Label Appeal")
dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, acid_index), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "acid_index", fill = "Target") +
ggtitle("Mosaic Plot : Acid Index")
dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, stars), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "stars", fill = "Target") +
ggtitle("Mosaic Plot : Stars")
metaDataTrain
# corrplot
cor(dfTrain, method = "pearson", use = "complete.obs") %>%
corrplot::corrplot(., method = "shade", type = "upper")
# density curve
dfGather <- dfTrain %>%
dplyr::select(-label_appeal, -acid_index, -stars) %>%
dplyr::mutate(target = as.factor(target)) %>%
tidyr::gather(key, value, -target)
ggplot(dfGather, aes(value, color = target)) +
geom_density() +
geom_vline(data = aggregate(value ~ target + key, dfGather, median),
aes(xintercept = value,
color = target),
linetype = "dashed") +
facet_wrap(~ key, nrow = 5, scales = "free")
# mosaic plot
dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, label_appeal), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "label_appeal", fill = "Target") +
ggtitle("Mosaic Plot : Label Appeal")
dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, acid_index), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "acid_index", fill = "Target") +
ggtitle("Mosaic Plot : Acid Index")
dfTrain %>%
ggplot(.) +
geom_mosaic(aes(x = product(target, stars), fill = as.factor(target)), na.rm = TRUE) +
labs(x = "stars", fill = "Target") +
ggtitle("Mosaic Plot : Stars")
metaDataEval
metaDataTrain
preProcValues <- preProcess(dfTrain, method = c("medianImpute"))
dfTrain <- predict(preProcValues, dfTrain)
colSums(is.na(dfTrain))
# impute - dfTrain
preProcValues <- preProcess(dfTrain, method = c("medianImpute"))
dfTrain <- predict(preProcValues, dfTrain)
# impute - dfEval
preProcValues <- preProcess(dfEval, method = c("medianImpute"))
dfEval <- predict(preProcValues, dfEval)
# check again
sapply(list(dfTrain, dfEval), function(x) colSums(is.na(x)))
metaDataEval
index = sample(1:nrow(dfTrain), prob = .7)
index = sample(1:nrow(dfTrain), size = nrow(dfTrain) * .7)
index
index = sample(1:nrow(dfTrain), size = nrow(dfTrain) * .7, replace = FALSE)
# impute - dfTrain
preProcValues <- preProcess(dfTrain, method = c("medianImpute"))
dfTrain <- predict(preProcValues, dfTrain)
# impute - dfEval
preProcValues <- preProcess(dfEval, method = c("medianImpute"))
dfEval <- predict(preProcValues, dfEval)
# check again
sapply(list(dfTrain, dfEval), function(x) colSums(is.na(x)))
# split data
index = sample(1:nrow(dfTrain), size = nrow(dfTrain) * .7, replace = FALSE)
trainSet <- dfTrain[index, ]
testSet <- dfTrain[-index, ]
colSums(is.na(dfEval))
head(dfEval)
colSums(is.na(dfTrain))
poisson_model_1 <- glm(target ~ ., family = "poisson", data = trainSet)
?zeroinfl
packages <- c('tidyverse', 'sqldf', 'broom', 'caret', 'kableExtra', 'janitor', 'Hmisc', 'MASS', 'corrplot', 'Metrics', 'purrr', 'janitor', 'gridExtra', 'ggmosaic', 'pscl')
pacman::p_load(char = packages)
?vuong
# poisson models
poisson_model_1 <- glm(target ~ ., family = "poisson", data = trainSet)
poisson_model_1 <- step(poisson_model_1, direction = "backward")
summary(poisson_model_1)
poisson_model_2 <- pscl::zeroinfl(target ~ ., data = trainSet)
summary(poisson_model_2)
poisson_model_2$coefficients
# Vuong
pscl::vuong(poisson_model_1, poisson_model_2)
pscl::vuong(poisson_model_1, poisson_model_2) %>% broom::tidy
pscl::vuong(poisson_model_1, poisson_model_2) %>% summary %>% broom::tidy
pscl::vuong(poisson_model_1, poisson_model_2) %>% summary
?glm.nb
metaDataTrain
# negative binomial models
negative_binomial_3 <- glm.nb(target ~ ., data = trainSet)
summary(negative_binomial_3)
# let's remove two variables and try again
negative_binomial_4 <- glm.nb(target ~ ., data = trainSet %>% dplyr::select(-fixed_acidity, -residual_sugar))
summary(negative_binomial_4)
# negative binomial models
negative_binomial_3 <- glm.nb(target ~ ., data = trainSet)
summary(negative_binomial_3)
# let's remove two variables and try again
negative_binomial_4 <- glm.nb(target ~ ., data = trainSet %>% dplyr::select(-fixed_acidity, -residual_sugar, -density))
summary(negative_binomial_4)
# impute - dfTrain
preProcValues <- preProcess(dfTrain, method = c("medianImpute"))
dfTrain <- predict(preProcValues, dfTrain)
# impute - dfEval
preProcValues <- preProcess(dfEval, method = c("medianImpute"))
dfEval <- predict(preProcValues, dfEval)
# check again
sapply(list(dfTrain, dfEval), function(x) colSums(is.na(x)))
# split data
set.seed(1234)
index = sample(1:nrow(dfTrain), size = nrow(dfTrain) * .7, replace = FALSE)
trainSet <- dfTrain[index, ]
testSet <- dfTrain[-index, ]
# poisson models
poisson_model_1 <- glm(target ~ ., family = "poisson", data = trainSet)
poisson_model_1 <- step(poisson_model_1, direction = "backward")
summary(poisson_model_1)
poisson_model_2 <- pscl::zeroinfl(target ~ ., data = trainSet)
summary(poisson_model_2)
poisson_model_2$coefficients
# Vuong comparison
pscl::vuong(poisson_model_1, poisson_model_2)
# negative binomial models
negative_binomial_3 <- glm.nb(target ~ ., data = trainSet)
summary(negative_binomial_3)
# let's remove two variables and try again
negative_binomial_4 <- glm.nb(target ~ ., data = trainSet %>% dplyr::select(-fixed_acidity, -residual_sugar, -density))
summary(negative_binomial_4)
# negative binomial models
negative_binomial_3 <- glm.nb(target ~ ., data = trainSet)
summary(negative_binomial_3)
# let's remove two variables and try again
negative_binomial_4 <- glm.nb(target ~ ., data = trainSet %>% dplyr::select(-fixed_acidity, -residual_sugar))
summary(negative_binomial_4)
multi_linear_5 <- lm(target ~ ., trainSet)
multi_linear_5 <- step(multi_linear_5, direction = 'backward')
summary(multi_linear_5)
step <- MASS::stepAIC(multi_linear_5, trace = FALSE)
step$anova
# multi-linear model
multi_linear_5 <- lm(target ~ ., trainSet)
multi_linear_5 <- step(multi_linear_5, direction = 'backward')
summary(multi_linear_5)
step <- MASS::stepAIC(multi_linear_5, trace = FALSE)
step$anova
multi_linear_6 <- lm(target ~ volatile_acidity + citric_acid + chlorides + free_sulfur_dioxide +
total_sulfur_dioxide + density + p_h + sulphates + alcohol +
label_appeal + acid_index + stars,
data = trainSet)
summary(multi_linear_6)
# multi-linear model
multi_linear_5 <- lm(target ~ ., trainSet)
multi_linear_5 <- step(multi_linear_5, direction = 'backward')
summary(multi_linear_5)
# try two degree of interaction
multi_linear_6 <- lm(target ~.^2, trainSet)
multi_linear_6 <- step(multi_linear_6, direction = 'backward')
summary(multi_linear_6)
summary(multi_linear_6)
summary(multi_linear_5)
summary(multi_linear_6)
summary(multi_linear_6)
# poisson model
targetMean <- round(mean(trainSet$target), 3)
targetVar <- round(var(trainSet$target), 3)
targetMean
targetVar
# poisson model
targetMean <- round(mean(trainSet$target), 3)
targetVar <- round(var(trainSet$target), 3)
print(paste0("the mean of the targt is approximately ", targetMean))
print(paste0("the variance of the targt is approximately ", targetVar))
dfTest %>% head
testSet %>% dim
ls()
# prediction
testSet <- testSet %>%
dplyr::mutate(pred_nb_3 = round(predict(negative_binomial_3, newdata = testSet, type = "response"), 0),
pred_nb_4 = round(predict(negative_binomial_4, newdata = testSet, type = "response"), 0),
pred_lm_5 = round(predict(multi_linear_5, newdata = testSet, type = "response"), 0),
pred_lm_6 = round(predict(multi_linear_6, newdata = testSet, type = "response"), 0))
sum(isTRUE(testSet$pred_nb_3 == testSet$target))
testSet$pred_nb_3 == testSet$target
(testSet$pred_nb_3 == testSet$target)
sum(isTRUE(testSet$pred_nb_3 == testSet$target))
# prediction
testSet <- testSet %>%
dplyr::mutate(pred_nb_3 = round(predict(negative_binomial_3, newdata = testSet, type = "response"), 0),
pred_nb_4 = round(predict(negative_binomial_4, newdata = testSet, type = "response"), 0),
pred_lm_5 = round(predict(multi_linear_5, newdata = testSet, type = "response"), 0),
pred_lm_6 = round(predict(multi_linear_6, newdata = testSet, type = "response"), 0),
pred_nb_3_accuracy = dplyr::case_when(pred_nb_3 == target ~ 1, TRUE ~ 0),
pred_nb_4_accuracy = dplyr::case_when(pred_nb_4 == target ~ 1, TRUE ~ 0),
pred_lm_5_accuracy = dplyr::case_when(pred_lm_5 == target ~ 1, TRUE ~ 0),
pred_lm_6_accuracy = dplyr::case_when(pred_lm_6 == target ~ 1, TRUE ~ 0))
lapply(testSet %>% dplyr::select(pred_nb_3_accuracy, pred_nb_4_accuracy, pred_lm_5_accuracy, pred_lm_6_accuracy),
sum) %>% unlist
accuracy / nrow(testSet)
accuracy <- lapply(testSet %>% dplyr::select(pred_nb_3_accuracy, pred_nb_4_accuracy, pred_lm_5_accuracy, pred_lm_6_accuracy),
sum) %>% unlist
accuracy / nrow(testSet)
round(accuracy / nrow(testSet), 2) * 100
paste0(round(accuracy / nrow(testSet), 2) * 100, "%")
round(accuracy / nrow(testSet), 3)
negative_binomial_3$residuals
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2))
mse
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2)) %>% unlist
mse
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2))
names(mse) <- c("negative binomial model 3", "negative binomial model 4", "multi-linear model 5", "multi-linear model 6")
mse
round(mse, 3)
lapply(mse, function(x) round(x, 3))
sapply(mse, function(x) round(x, 3))
# prediction accuracy
testSet <- testSet %>%
dplyr::mutate(pred_nb_3 = round(predict(negative_binomial_3, newdata = testSet, type = "response"), 0),
pred_nb_4 = round(predict(negative_binomial_4, newdata = testSet, type = "response"), 0),
pred_lm_5 = round(predict(multi_linear_5, newdata = testSet, type = "response"), 0),
pred_lm_6 = round(predict(multi_linear_6, newdata = testSet, type = "response"), 0),
pred_nb_3_accuracy = dplyr::case_when(pred_nb_3 == target ~ 1, TRUE ~ 0),
pred_nb_4_accuracy = dplyr::case_when(pred_nb_4 == target ~ 1, TRUE ~ 0),
pred_lm_5_accuracy = dplyr::case_when(pred_lm_5 == target ~ 1, TRUE ~ 0),
pred_lm_6_accuracy = dplyr::case_when(pred_lm_6 == target ~ 1, TRUE ~ 0))
accuracy <- lapply(testSet %>% dplyr::select(pred_nb_3_accuracy, pred_nb_4_accuracy, pred_lm_5_accuracy, pred_lm_6_accuracy),
sum) %>% unlist
round(accuracy / nrow(testSet), 3)
# mean squared error
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2))
names(mse) <- c("negative binomial model 3", "negative binomial model 4", "multi-linear model 5", "multi-linear model 6")
sapply(mse, function(x) round(x, 3))
# prediction accuracy
testSet <- testSet %>%
dplyr::mutate(pred_nb_3 = round(predict(negative_binomial_3, newdata = testSet, type = "response"), 0),
pred_nb_4 = round(predict(negative_binomial_4, newdata = testSet, type = "response"), 0),
pred_lm_5 = round(predict(multi_linear_5, newdata = testSet, type = "response"), 0),
pred_lm_6 = round(predict(multi_linear_6, newdata = testSet, type = "response"), 0),
pred_nb_3_accuracy = dplyr::case_when(pred_nb_3 == target ~ 1, TRUE ~ 0),
pred_nb_4_accuracy = dplyr::case_when(pred_nb_4 == target ~ 1, TRUE ~ 0),
pred_lm_5_accuracy = dplyr::case_when(pred_lm_5 == target ~ 1, TRUE ~ 0),
pred_lm_6_accuracy = dplyr::case_when(pred_lm_6 == target ~ 1, TRUE ~ 0))
accuracy <- lapply(testSet %>% dplyr::select(pred_nb_3_accuracy, pred_nb_4_accuracy, pred_lm_5_accuracy, pred_lm_6_accuracy),
sum) %>% unlist
round(accuracy / nrow(testSet), 3)
# mean squared error
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2))
names(mse) <- c("negative_binomial_3", "negative_binomial_4", "multi_linear_5", "multi_linear_6")
sapply(mse, function(x) round(x, 3))
barplot(dfTrain$target)
barplot(table(dfTrain$target))
negative_binomial_3 %>% summary
dfEval <- dfEval %>%
dplyr::mutate(pred = round(predict(negative_binomial_4, newdata = dfEval, type = "response"), 0))
# prediction accuracy
testSet <- testSet %>%
dplyr::mutate(pred_nb_3 = round(predict(negative_binomial_3, newdata = testSet, type = "response"), 0),
pred_nb_4 = round(predict(negative_binomial_4, newdata = testSet, type = "response"), 0),
pred_lm_5 = round(predict(multi_linear_5, newdata = testSet, type = "response"), 0),
pred_lm_6 = round(predict(multi_linear_6, newdata = testSet, type = "response"), 0),
pred_nb_3_accuracy = dplyr::case_when(pred_nb_3 == target ~ 1, TRUE ~ 0),
pred_nb_4_accuracy = dplyr::case_when(pred_nb_4 == target ~ 1, TRUE ~ 0),
pred_lm_5_accuracy = dplyr::case_when(pred_lm_5 == target ~ 1, TRUE ~ 0),
pred_lm_6_accuracy = dplyr::case_when(pred_lm_6 == target ~ 1, TRUE ~ 0))
accuracy <- lapply(testSet %>% dplyr::select(pred_nb_3_accuracy, pred_nb_4_accuracy, pred_lm_5_accuracy, pred_lm_6_accuracy),
sum) %>% unlist
round(accuracy / nrow(testSet), 3)
# mean squared error
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2))
names(mse) <- c("negative_binomial_3", "negative_binomial_4", "multi_linear_5", "multi_linear_6")
sapply(mse, function(x) round(x, 3))
# evaluation set
dfEval <- dfEval %>%
dplyr::mutate(pred = round(predict(negative_binomial_4, newdata = dfEval, type = "response"), 0))
# barplot for evaluation set (side by side with the train set)
par(mfrow = c(1, 2))
barplot(table(dfTrain$target), main = "Train Set : Target")
barplot(table(dfEval$pred), main = "Evaluation Set : Target")
table(dfEval$pred)
table(dfTrain$target)
# prediction accuracy
testSet <- testSet %>%
dplyr::mutate(pred_nb_3 = round(predict(negative_binomial_3, newdata = testSet, type = "response"), 0),
pred_nb_4 = round(predict(negative_binomial_4, newdata = testSet, type = "response"), 0),
pred_lm_5 = round(predict(multi_linear_5, newdata = testSet, type = "response"), 0),
pred_lm_6 = round(predict(multi_linear_6, newdata = testSet, type = "response"), 0),
pred_nb_3_accuracy = dplyr::case_when(pred_nb_3 == target ~ 1, TRUE ~ 0),
pred_nb_4_accuracy = dplyr::case_when(pred_nb_4 == target ~ 1, TRUE ~ 0),
pred_lm_5_accuracy = dplyr::case_when(pred_lm_5 == target ~ 1, TRUE ~ 0),
pred_lm_6_accuracy = dplyr::case_when(pred_lm_6 == target ~ 1, TRUE ~ 0))
accuracy <- lapply(testSet %>% dplyr::select(pred_nb_3_accuracy, pred_nb_4_accuracy, pred_lm_5_accuracy, pred_lm_6_accuracy),
sum) %>% unlist
round(accuracy / nrow(testSet), 3)
# mean squared error
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2))
names(mse) <- c("negative_binomial_3", "negative_binomial_4", "multi_linear_5", "multi_linear_6")
sapply(mse, function(x) round(x, 3))
# evaluation set
dfEval <- dfEval %>%
dplyr::mutate(pred = round(predict(negative_binomial_4, newdata = dfEval, type = "response"), 0))
# barplot for evaluation set (side by side with the train set)
par(mfrow = c(1, 2))
barplot(table(dfTrain$target), main = "Train Set : Target")
barplot(table(dfEval$pred), main = "Evaluation Set : Target Prediction")
lapply(list(`wine-training` = dfTrain, `wine-evaluation` = dfEval), function(x) dim(x))
?step
?stats::step
multi_linear_5 <- step(multi_linear_5, direction = 'backward', trace = -1)
multi_linear_5 <- step(multi_linear_5, direction = 'backward', trace = -1) %>% invisible
summary(negative_binomial_4)
print(round(accuracy / nrow(testSet), 3))
print(sapply(mse, function(x) round(x, 3)))
print(sapply(mse, function(x) round(x, 3))) %>% kable()
print(round(accuracy / nrow(testSet), 3)) %>% kable()
print(sapply(mse, function(x) round(x, 3))) %>% kable()
# prediction accuracy
testSet <- testSet %>%
dplyr::mutate(pred_nb_3 = round(predict(negative_binomial_3, newdata = testSet, type = "response"), 0),
pred_nb_4 = round(predict(negative_binomial_4, newdata = testSet, type = "response"), 0),
pred_lm_5 = round(predict(multi_linear_5, newdata = testSet, type = "response"), 0),
pred_lm_6 = round(predict(multi_linear_6, newdata = testSet, type = "response"), 0),
pred_nb_3_accuracy = dplyr::case_when(pred_nb_3 == target ~ 1, TRUE ~ 0),
pred_nb_4_accuracy = dplyr::case_when(pred_nb_4 == target ~ 1, TRUE ~ 0),
pred_lm_5_accuracy = dplyr::case_when(pred_lm_5 == target ~ 1, TRUE ~ 0),
pred_lm_6_accuracy = dplyr::case_when(pred_lm_6 == target ~ 1, TRUE ~ 0))
accuracy <- lapply(testSet %>% dplyr::select(pred_nb_3_accuracy, pred_nb_4_accuracy, pred_lm_5_accuracy, pred_lm_6_accuracy),
sum) %>% unlist
print(round(accuracy / nrow(testSet), 3)) %>% kable()
# mean squared error
mse <- lapply(list(negative_binomial_3, negative_binomial_4, multi_linear_5, multi_linear_6),
function(x) mean(x$residuals ^2))
names(mse) <- c("negative_binomial_3: mse", "negative_binomial_4: mse", "multi_linear_5: mse", "multi_linear_6: mse")
print(sapply(mse, function(x) round(x, 3))) %>% kable()
# evaluation set
dfEval <- dfEval %>%
dplyr::mutate(pred = round(predict(negative_binomial_4, newdata = dfEval, type = "response"), 0))
# barplot for evaluation set (side by side with the train set)
par(mfrow = c(1, 2))
barplot(table(dfTrain$target), main = "Train Set : Target")
barplot(table(dfEval$pred), main = "Evaluation Set : Target Prediction")
