---
title: "project2_nonlinear_regression_JN"
author: "Jimmy Ng"
date: "7/12/2020"
output: html_document
---

```{r setup, include = FALSE, warning = FALSE, collapse = TRUE, result = "hide", echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load packages
packages <- c('tidyverse', 'caret', 'mlbench', 'mice', 'kableExtra', 'earth', 'VIM', 'DMwR', 'parallel', 'doParallel', 'MLmetrics')
pacman::p_load(char = packages)

# read data
bev_model <- readxl::read_excel('StudentData_TO_MODEL.xlsx',col_names = TRUE, sheet = 'Subset')
bev_score <- readxl::read_excel('StudentEvaluation_TO_PREDICT.xlsx',col_names = TRUE, sheet = 'Subset (2)')

# remove NA pH records
bev_model <- bev_model[complete.cases(bev_model[,26]),]
# update NA Brand Code records to "U"
bev_model$`Brand Code`[is.na(bev_model$`Brand Code`)] <- 'U'

bev_model_i <- as.data.frame(bev_model[, !names(bev_model) %in% c("Brand Code", "PH")])

# https://www.r-bloggers.com/missing-value-treatment/
bev_model_impute <- knnImputation(bev_model_i, k = 10)
bev_model_impute$pH <- bev_model$PH
bev_model_impute$'Brand Code' <- bev_model$`Brand Code`

# split into train, test set
set.seed(3456)
trainIndex <- createDataPartition(bev_model_impute$pH, p = .8, 
                                  list = FALSE, 
                                  times = 1)
bev_model_train <- bev_model_impute[ trainIndex,]
bev_model_test  <- bev_model_impute[-trainIndex,]

# Train data Test set 
X_test <- bev_model_test[,-32] # Dropped PH
Y_test <- bev_model_test[,32] # Only PH

# Score data 
X_Stest <- bev_score[,-26] # Dropped PH

# metadata for X_Stest
metadata <- colSums(is.na(X_Stest)) %>% 
        as.data.frame() %>% 
        tibble::rownames_to_column() %>%
        dplyr::select(field = rowname, missing = ".") %>%
        dplyr::inner_join(., sapply(X_Stest, class) %>% 
                                  as.data.frame() %>% 
                                  tibble::rownames_to_column() %>%
                                  dplyr::select(field = rowname, class = "."),
                          by = c("field"))

X_Stest$`Brand Code`[is.na(X_Stest$`Brand Code`)] <- 'U'
temp_names <- names(X_Stest)
# names have to be cleaned in order to use mice
X_Stest <- janitor::clean_names(X_Stest)
# I have to switch and use mice as the knnImputation doesn't work for me
X_Stest_mice <- mice::mice(X_Stest, method = "pmm", seed = 1234)
X_Stest_impute <- mice::complete(X_Stest_mice, 1)
X_Stest <- X_Stest_impute
names(X_Stest) <- temp_names
colSums(is.na(X_Stest))

# very weird error - the evaluation set must have its columns in the same order as the train set; otherwise the MARS model will not be applicable to run for prediction!
X_Stest <- X_Stest %>%
        dplyr::select(all_of(names(bev_model_impute)[!names(bev_model_impute) %in% c("pH")]))

Y_Stest <- bev_score[,26] # Only PH
```

```{r multicore_processing, result = "hide", warning = FALSE, collapse = TRUE}
# detect, use multicores
numCores <- parallel::detectCores()

# create a simple cluster on the local machine using all available threads
cl <- parallel::makeCluster(detectCores(), methods = FALSE)

# register our cluster
doParallel::registerDoParallel(cl)
```

## MARS

```{r MARS, warning = FALSE, collapse = TRUE}
# model
set.seed(1234)
marsModel <- caret::train(x = bev_model_train %>% dplyr::select(-pH), 
                          y = bev_model_train %>% dplyr::select(pH) %>% .$pH,
                          method = "earth",
                          preProcess = c("center", "scale"),
                          tuneGrid = expand.grid(degree = 1:3, nprune = 1:30),
                          trControl = trainControl(method = "cv"))

# ggplot
ggplot(marsModel) + labs(title = "MARS Cross-Validated RMSE Profile") + theme_classic()

# importance (top 5)
marsPerformance <- caret::varImp(marsModel)
marsPerformance$importance %>% 
        as.data.frame() %>%
        tibble::rownames_to_column() %>%
        dplyr::mutate(name = forcats::fct_inorder(rowname)) %>%
        arrange(desc(Overall)) %>%
        head(5) %>%
        ggplot(., aes(x = reorder(name, Overall), y = Overall)) + 
        geom_point() + 
        geom_segment(aes(x = name, xend = name, y = 0, yend = Overall)) + 
        ggtitle("MARS: Top 5 Variables") +
        labs(x = "Variable", y = "Importance") +
        coord_flip() +
        theme_minimal()

# Validation on the hold-out set 
marsPred <- predict(marsModel, newdata = bev_model_test) 
marsKPI <- postResample(pred = marsPred, obs = Y_test)
marsMAPE <- MLmetrics::MAPE(predict(marsModel, X_test), Y_test)
```

## SVM

```{r SVM, warning = FALSE, collapse = TRUE}
# model
set.seed(1234)
svmModel <- caret::train(pH ~., bev_model_train,
                         method = "svmRadial",
                         preProcess = c("center", "scale"),
                         tuneLength = 14,
                         trControl = trainControl(method = "cv"))

# ggplot
ggplot(svmModel) + labs(title = "SVM Cross-Validated RMSE Profile") + theme_gray()

# importance (top 5)
svmPerformance <- caret::varImp(svmModel)
svmPerformance$importance %>% 
        as.data.frame() %>%
        tibble::rownames_to_column() %>%
        dplyr::mutate(name = forcats::fct_inorder(rowname)) %>%
        arrange(desc(Overall)) %>%
        head(5) %>%
        ggplot(., aes(x = reorder(name, Overall), y = Overall)) + 
        geom_point() + 
        geom_segment(aes(x = name, xend = name, y = 0, yend = Overall)) + 
        ggtitle("SVM: Top 5 Variables") +
        labs(x = "Variable", y = "Importance") +
        coord_flip() +
        theme_minimal()

# Validation on the hold-out set 
svmPred <- predict(svmModel, newdata = bev_model_test) 
svmKPI <- postResample(pred = svmPred, obs = Y_test)
svmMAPE <- MLmetrics::MAPE(predict(svmModel, X_test), Y_test)
```

## KNN

```{r KNN, warning = FALSE, collapse = TRUE}
# model
set.seed(1234)
knnModel <- caret::train(pH ~ ., bev_model_train,
                         method = "knn", 
                         preProcess = c('center', 'scale'), 
                         tuneLength = 10, 
                         trControl = trainControl(method = "cv"))

# ggplot
ggplot(knnModel) + labs(title = "KNN Cross-Validated RMSE Profile") + theme_bw()

# importance (top 5)
knnPerformance <- caret::varImp(knnModel)
knnPerformance$importance %>% 
        as.data.frame() %>%
        tibble::rownames_to_column() %>%
        dplyr::mutate(name = forcats::fct_inorder(rowname)) %>%
        arrange(desc(Overall)) %>%
        head(5) %>%
        ggplot(., aes(x = reorder(name, Overall), y = Overall)) + 
        geom_point() + 
        geom_segment(aes(x = name, xend = name, y = 0, yend = Overall)) + 
        ggtitle("KNN: Top 5 Variables") +
        labs(x = "Variable", y = "Importance") +
        coord_flip() +
        theme_minimal()

# Validation on the hold-out set 
knnPred <- predict(knnModel, newdata = bev_model_test) 
knnKPI <- postResample(pred = knnPred, obs = Y_test)
knnMAPE <- MLmetrics::MAPE(predict(knnModel, X_test), Y_test)
```

### MARS model summary
```{r MARS_output, echo = FALSE, collapse = TRUE}
marsOutput <- marsKPI %>% 
        as.data.frame %>%
        tibble::rownames_to_column() %>%
        dplyr::select(KPI = rowname, MARS.Model = ".") %>%
        dplyr::mutate(MAPE = marsMAPE)

marsOutput %>%
        kable %>%
        kable_styling()
```

### SVM model summary
```{r SVM_output, echo = FALSE, collapse = TRUE}
svmOutput <- svmKPI %>% 
        as.data.frame %>%
        tibble::rownames_to_column() %>%
        dplyr::select(KPI = rowname, SVM.Model = ".") %>%
        dplyr::mutate(MAPE = svmMAPE)

svmOutput %>%
        kable %>%
        kable_styling()
```

### KNN model summary
```{r KNN_output, echo = FALSE, collapse = TRUE}
knnOutput <- knnKPI %>% 
        as.data.frame %>%
        tibble::rownames_to_column() %>%
        dplyr::select(KPI = rowname, KNN.Model = ".") %>%
        dplyr::mutate(MAPE = knnMAPE)

knnOutput %>%
        kable %>%
        kable_styling()
```

The performance of these models are very similar, but SVM seems to do slightly better than MARS and KNN. We can apply the model to the evaluation set. 

```{r SVM_prediction, echo = FALSE, collapse = TRUE, fig.width = 10, fig.height = 8}
svmModel_prediction <- predict(svmModel, newdata = X_Stest)

par(mfrow=c(2, 2))
plot(bev_model_impute$pH, main = 'Plot of PH from Train data')
plot(svmModel_prediction, main = 'Plot of PH from Predicted (evaluation) data')
boxplot(bev_model_impute$pH, main = 'Boxplot of PH from Train data')
boxplot(svmModel_prediction, main = 'Boxplot of PH from Predicted (evaluation) data')

# write to file
# write.csv(svmModel_prediction, file = "svmModel_prediction_for_PH.csv", row.names = FALSE)
```

```{r multicore_processing_end, result = "hide", warning = FALSE, collapse = TRUE}
# stop the cluster
parallel::stopCluster(cl)
```


