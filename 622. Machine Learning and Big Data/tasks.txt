### HW due Friday
# HW1 due 2/19 
# HW2 due 3/12
# HW3 due 4/9
# HW4 due 4/30
# Final Project 5/23 (Sunday)

### Discussion due Friday
# + responses to 2 peers

### Meet Up, every other week 
# Wednesday@630pm, starts at Feb 10, 2021

############################################################################################################# 

### Weekly Materials

#############################
>> Week 1 (Jan 29 - Feb 4)
- ISLR: Ch 1 and 2

#############################
>> Week 2 (Feb 5 - Feb 12)
- ISLR: Ch 3.1, 3.2, 3.3, 4.1, 4.2, 4.3
- ESL: Ch 4.4.1

- Helpful videos: 

Statistical learning and models: 
https://www.youtube.com/watch?v=WjyuiK5taS8&list=PL5-da3qGB5IDvuFPNoSqheihPOQNJpzyy 

Logistic Regression: 
https://www.youtube.com/watch?v=WjyuiK5taS8&list=PL5-da3qGB5IDvuFPNoSqheihPOQNJpzyy

Multivariate logistic regression:
https://www.youtube.com/watch?v=MpX8rVv_u4E&list=PL5-da3qGB5IC4vaDba5ClatUmFppXLAhE

#############################
>> Week 3 (Feb 12 - Feb 19)

- Homework #1 due on Feb 19. 

- Discussion Board week #3 due Feb 19.

- Reading materials:
Elements of Statistical Learning: Ch: 4 (please note that we already covered 4.4, logistic regression). This is the rest of the readings on Discriminant Analysis
Introduction to Statistical Analysis: Ch: 4 (we already covered 4.3, logistic regression). 

- Helpful videos:
Discriminant Analysis: https://youtu.be/RfrGiG1Hm3M
Univariate LDA: https://youtu.be/QG0pVJXT6EU
Multivariate LDA: https://youtu.be/X4VDZDp2vqw
QDA and Naive Bayes: https://youtu.be/6FiNGTYAOAA
R-lab for LDA: https://youtu.be/2cl7JiPzkBY;
R-lab for kNN: https://youtu.be/9TVVF7CS3F4 (we are looking at kNN lab already. More detailed readings on this matter will be coming up). 

#############################
>> Week 4 (Feb 19 - Feb 26)

Weekly materials
This week, our formal readings from the book will be a little lighter than some of the practical resources we will look at. The focus is to develop a solid understanding of KNN and Naive Bayes as far as conducting the analysis is concerned. We will be a little light on the theoretical readings. 

Tasks: 

1. Discussion board

2. HW# 2 is assigned

3. Reading and learning materials: 

- KNN R resources: https://www.geeksforgeeks.org/k-nn-classifier-in-r-programming/

- A practical guide on KNN https://www.listendata.com/2017/12/k-nearest-neighbor-step-by-step-tutorial.html

- Naïve Bayes Classifier R resource. https://uc-r.github.io/naive_bayes

- In order to have a good grasp of LDA, Naive Bayes and Logistic Regression in terms of how they all compare and contrast, this is a good set of lecture slides: https://mdav.ece.gatech.edu/ece-6254-spring2017/notes/05-logistic-regression.pdf 

- Though it is a bit less academic, I like this video in terms of how clearly it explains the Naive Bayes ideas. https://www.youtube.com/watch?v=O2L2Uv9pdDA

- From the same producer, the Gaussian Naive Bayes: https://youtu.be/H3EjCKtlVog

- ESL: Chapter section 6.6, focus on Naïve Bayes Classifier (6.6.3)

- ESL: Section 7.10 (Cross validation). This may be helpful for HW#3 when you look at the KNN problem. This is an important topic and we will revisit this topic a couple of times.

- ISLR: Chapter 6 (optional). You probably know most of these in terms of variable selection. However, reading the section 6.2 will help the understanding of bias-variance tradeoff, the shrinkage/regularization methods, and variable selection.

- (Optional) Discriminative and generative classifiers: how Logistic Regression differs from Naive Bayes https://papers.nips.cc/paper/2001/file/7b7a53e239400a13bd6be6c91c4f6c4e-Paper.pdf

#############################
>> Week 5 (Feb 26 - Mar 5)

1. Discussion board

2. HW# 2 is assigned

3. Reading and learning materials:  

          ESL: Ch: 9.1, 9.2;  ISLR: Ch: 8.1

Lecture slides: https://web.stanford.edu/~hastie/MOOC-Slides/trees.pdf (These slides go into next week's materials as well. For this week, focus till      slide # 30)

Videos:

Decision Trees: https://www.youtube.com/watch?v=6ENTbK3yQUQ&list=PL5-da3qGB5IB23TLuA8ZgVGC8hV8ZAdGh

Pruning a Decision Tree: https://www.youtube.com/watch?v=GfPR7Xhdokc&list=PL5-da3qGB5IB23TLuA8ZgVGC8hV8ZAdGh

Classification Trees: https://www.youtube.com/watch?v=hPEJoITBbQ4&list=PL5-da3qGB5IB23TLuA8ZgVGC8hV8ZAdGh

#############################
>> Week 6 (Mar 5 - Mar 12)

This week and the next, we will be digging into boosting and additive models. 

Homework #2 due March 19.

Discussion Board # 6

ISLR: 8.2, 8.3. 
ESL: 9.3 - 9.7

Lecture slides: https://web.stanford.edu/~hastie/MOOC-Slides/trees.pdf (slide#31 onward)

Video: Bagging and Random Forests
Video: Boosting and Variable Importance
Video: Decision Trees Lab
Video: Random Forests and Boosting

#############################
>> Week 7 (Mar 12 - Mar 19)

Boosting some more!
This week, we dig into boosting and additive models even more. Next week, we will be looking at Support Vector Machine. 

Discussion Board # 7
Homework # 2 due on March 19
Homework # 3 will be posted
Reading: ESL: Chapter 10 (Boosting and Additive Trees)
Helpful lectures :
Not a formal academic source,  but I think these are helpful: AdaBoost explanation: I like the clarity behind this  video: https://www.youtube.com/watch?v=LsK-xG1cLYA
Gradient Boosting:
Part 1 (for regression; continuous outcome);
Part 2 (more theoretical);
Part 3 (more practical, classification problem; might be helpful for homework # 3);
Part 4 (more theoretical).
Quite long, especially if you go through all three lecture videos. But if you have the time, very much worth it. http://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote19.html



